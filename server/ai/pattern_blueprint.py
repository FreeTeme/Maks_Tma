from datetime import datetime, timedelta
from flask import Blueprint, request, jsonify
import pandas as pd
import time
from pathlib import Path
from ai.main import CACHE_DIR
from ai.main import (
    analyze_selected_pattern, 
    api_get_ohlcv_data,  
    api_get_data_bounds,
    get_supported_symbols,
    normalize_symbol,
    check_data_updates,        
    get_latest_ohlcv,
    check_data_freshness,
    get_ohlcv_data, 
    save_to_cache, 
    get_cache_key,
    fetch_binance_ohlcv_fast
)


# –°–æ–∑–¥–∞–µ–º Blueprint –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
pattern_bp = Blueprint('pattern', __name__, url_prefix='/api/pattern')

CACHE_DIR = Path("pattern_cache")
CACHE_DIR.mkdir(exist_ok=True)
# –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∫—ç—à
data_cache = {}
CACHE_TIMEOUT = 300  # 5 –º–∏–Ω—É—Ç

@pattern_bp.route('/symbols', methods=['GET'])
def api_symbols():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —Ç–æ—Ä–≥–æ–≤—ã—Ö –ø–∞—Ä"""
    try:
        result = get_supported_symbols()
        return jsonify(result)
    except Exception as e:
        return jsonify({'success': False, 'message': str(e)}), 500

@pattern_bp.route('/bounds', methods=['GET'])
def pattern_bounds():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≥—Ä–∞–Ω–∏—Ü—ã –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    try:
        timeframe = request.args.get('timeframe', '1d')
        symbol = request.args.get('symbol', 'BTCUSDT')
        result = api_get_data_bounds(timeframe, symbol)
        return jsonify(result)
    except Exception as e:
        return jsonify({'success': False, 'message': str(e)}), 500

@pattern_bp.route('/ohlcv', methods=['GET'])
def api_ohlcv():
    """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è OHLCV –¥–∞–Ω–Ω—ã—Ö"""
    try:
        from_date = request.args.get('from')
        to_date = request.args.get('to')
        timeframe = request.args.get('timeframe', '1d')
        symbol = request.args.get('symbol', 'BTCUSDT')
        
        print(f"üì• –ó–∞–ø—Ä–æ—Å OHLCV: {symbol} {timeframe}")
        
        # –ü—Ä–æ—Å—Ç–æ–π –∫—ç—à
        cache_key = f"ohlcv_{symbol}_{timeframe}_{from_date}_{to_date}"
        
        if cache_key in data_cache:
            cached_data, timestamp = data_cache[cache_key]
            if time.time() - timestamp < CACHE_TIMEOUT:
                print(f"‚úÖ –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {symbol} {timeframe}")
                return jsonify(cached_data)
        
        result = api_get_ohlcv_data(from_date, to_date, timeframe, symbol)
        
        if result['success']:
            data_cache[cache_key] = (result, time.time())
            print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω—ã –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ: {symbol} {timeframe} - {len(result.get('candles', []))} —Å–≤–µ—á–µ–π")
            return jsonify(result)
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {symbol} {timeframe} - {result.get('message')}")
            return jsonify({'success': False, 'message': result['message']}), 500
            
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ api_ohlcv: {str(e)}")
        return jsonify({'success': False, 'message': str(e)}), 500

@pattern_bp.route('/analyze', methods=['POST'])
def analyze_pattern():
    """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–∞"""
    start_time = time.time()
    max_request_time = 120
    
    try:
        data = request.get_json()
        if not data:
            return jsonify({'success': False, 'message': 'No data provided'}), 400
            
        required_fields = ['num_candles', 'candles']
        
        if not all(field in data for field in required_fields):
            return jsonify({'success': False, 'message': 'Missing required fields'}), 400
        
        timeframe = data.get('timeframe', '1d')
        symbol = data.get('symbol', 'BTCUSDT')
        no_cache = data.get('no_cache', False)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞
        if time.time() - start_time > max_request_time:
            return jsonify({'success': False, 'message': 'Request timeout'}), 408
        
        # –ü—Ä–æ—Å—Ç–æ–π –∫—ç—à
        if not no_cache:
            pattern_hash = hash(str([c['open_time'] for c in data['candles']]))
            cache_key = f"analysis_{symbol}_{timeframe}_{pattern_hash}"
            
            if cache_key in data_cache:
                cached_result, timestamp = data_cache[cache_key]
                if time.time() - timestamp < CACHE_TIMEOUT:
                    return jsonify(cached_result)
        
        print(f"–ù–∞—á–∏–Ω–∞–µ–º –∞–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–∞: {data['num_candles']} —Å–≤–µ—á–µ–π, –ü–∞—Ä–∞: {symbol}, –¢–§: {timeframe}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º –∞–Ω–∞–ª–∏–∑–∞
        if time.time() - start_time > max_request_time:
            return jsonify({'success': False, 'message': 'Request timeout before analysis'}), 408
        
        result = analyze_selected_pattern(
            data['candles'], 
            data['num_candles'], 
            timeframe, 
            symbol, 
            no_cache=no_cache
        )
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø–æ—Å–ª–µ –∞–Ω–∞–ª–∏–∑–∞
        if time.time() - start_time > max_request_time:
            return jsonify({'success': False, 'message': 'Analysis timeout'}), 408
        
        if 'error' in result:
            return jsonify({'success': False, 'message': result['error']}), 500
        
        # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if not no_cache:
            pattern_hash = hash(str([c['open_time'] for c in data['candles']]))
            cache_key = f"analysis_{symbol}_{timeframe}_{pattern_hash}"
            data_cache[cache_key] = (result, time.time())
        
        total_time = time.time() - start_time
        print(f"–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {total_time:.2f} —Å–µ–∫—É–Ω–¥")
        
        return jsonify(result)
        
    except Exception as e:
        return jsonify({'success': False, 'message': str(e)}), 500

@pattern_bp.route('/force_update', methods=['POST'])
def force_update():
    """–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö"""
    try:
        symbol = request.args.get('symbol', 'BTCUSDT')
        timeframe = request.args.get('timeframe', '1d')
        
        print(f"üîÑ –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö: {symbol}, {timeframe}")
        
        normalized_symbol = normalize_symbol(symbol)
        
        # –û—á–∏—â–∞–µ–º –∫—ç—à
        cache_patterns = [f"ohlcv_{normalized_symbol}", f"full_data_{normalized_symbol}"]
        cleared_count = 0
        
        for cache_file in CACHE_DIR.glob("*.pkl"):
            if any(pattern in cache_file.name for pattern in cache_patterns):
                try:
                    cache_file.unlink()
                    cleared_count += 1
                except:
                    pass
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–≤–µ–∂–∏–µ –¥–∞–Ω–Ω—ã–µ
        fresh_data = get_ohlcv_data(timeframe, normalized_symbol)
        
        return jsonify({
            'success': True,
            'message': f'Data force updated for {normalized_symbol}',
            'cleared_cache_entries': cleared_count,
            'fresh_data_count': len(fresh_data) if not fresh_data.empty else 0
        })
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ force_update: {str(e)}")
        return jsonify({
            'success': False, 
            'message': f'Error in force update: {str(e)}'
        }), 500

@pattern_bp.route('/check_updates', methods=['GET'])
def check_updates():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –±–µ–∑ –ø–æ–ª–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏"""
    try:
        symbol = request.args.get('symbol', 'BTCUSDT')
        timeframe = request.args.get('timeframe', '1d')
        last_known = request.args.get('last_known')
        
        if not last_known:
            return jsonify({
                'success': False, 
                'message': 'last_known parameter is required'
            }), 400
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –∏–∑ main.py
        result = check_data_updates(symbol, timeframe, last_known)
        
        return jsonify({
            'success': True,
            **result
        })
        
    except Exception as e:
        print(f"Error in check_updates: {str(e)}")  # –î–æ–±–∞–≤—å—Ç–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        return jsonify({
            'success': False, 
            'message': f'Error checking updates: {str(e)}'
        }), 500

@pattern_bp.route('/incremental_update', methods=['GET'])
def incremental_update():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —Å –º–æ–º–µ–Ω—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è"""
    try:
        symbol = request.args.get('symbol', 'BTCUSDT')
        timeframe = request.args.get('timeframe', '1d')
        last_known = request.args.get('last_known')
        
        if not last_known:
            return jsonify({
                'success': False, 
                'message': 'last_known parameter is required'
            }), 400
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –∏–∑ main.py
        new_data = get_latest_ohlcv(symbol, timeframe, last_known)
        
        if new_data.empty:
            return jsonify({
                'success': True, 
                'has_updates': False,
                'message': 'No new data available'
            })
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞
        records = []
        for _, row in new_data.iterrows():
            open_time = row['date']
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º close_time –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞
            if timeframe == '1h':
                close_time = open_time + timedelta(hours=1)
            elif timeframe == '4h':
                close_time = open_time + timedelta(hours=4)
            elif timeframe == '1d':
                close_time = open_time + timedelta(days=1)
            elif timeframe == '1w':
                close_time = open_time + timedelta(weeks=1)
            else:
                close_time = open_time + timedelta(days=1)
            
            records.append({
                'open_time': open_time.strftime('%Y-%m-%dT%H:%M:%SZ'),
                'close_time': close_time.strftime('%Y-%m-%dT%H:%M:%SZ'),
                'open_price': float(row['open']),
                'close_price': float(row['close']),
                'high': float(row['high']),
                'low': float(row['low']),
                'volume': float(row['volume']),
                'timeframe': timeframe,
                'symbol': symbol
            })
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–∞–º—É—é —Å–≤–µ–∂—É—é –¥–∞—Ç—É –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
        latest_timestamp = new_data['date'].max().strftime('%Y-%m-%dT%H:%M:%SZ')
        
        return jsonify({
            'success': True,
            'has_updates': True,
            'new_candles': records,
            'latest_timestamp': latest_timestamp,
            'retrieved_count': len(records),
            'symbol': symbol,
            'timeframe': timeframe
        })
        
    except Exception as e:
        print(f"Error in incremental_update: {str(e)}")  # –î–æ–±–∞–≤—å—Ç–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        return jsonify({
            'success': False, 
            'message': f'Error fetching incremental data: {str(e)}'
        }), 500
    
@pattern_bp.route('/force_refresh', methods=['POST'])
def force_refresh():
    """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–∏–º–≤–æ–ª–∞"""
    try:
        data = request.get_json() or {}
        symbol = data.get('symbol', 'BTCUSDT')
        timeframe = data.get('timeframe', '1d')
        
        normalized_symbol = normalize_symbol(symbol)
        
        # –û—á–∏—â–∞–µ–º –∫—ç—à –¥–ª—è —ç—Ç–æ–π –ø–∞—Ä—ã
        keys_to_remove = [key for key in data_cache.keys() if normalized_symbol in key or symbol in key]
        for key in keys_to_remove:
            del data_cache[key]
        
        # –¢–∞–∫–∂–µ –æ—á–∏—â–∞–µ–º —Ñ–∞–π–ª–æ–≤—ã–π –∫—ç—à
        cache_patterns = [f"ohlcv_{normalized_symbol}", f"full_data_{normalized_symbol}"]
        for cache_file in CACHE_DIR.glob("*.pkl"):
            if any(pattern in cache_file.name for pattern in cache_patterns):
                try:
                    cache_file.unlink()
                except:
                    pass
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–≤–µ–∂–∏–µ –¥–∞–Ω–Ω—ã–µ
        from ai.main import get_ohlcv_data
        fresh_data = get_ohlcv_data(timeframe, normalized_symbol)
        
        return jsonify({
            'success': True,
            'message': f'Data refreshed for {normalized_symbol}',
            'cleared_cache_entries': len(keys_to_remove),
            'fresh_data_count': len(fresh_data) if not fresh_data.empty else 0
        })
        
    except Exception as e:
        return jsonify({
            'success': False, 
            'message': f'Error refreshing data: {str(e)}'
        }), 500

@pattern_bp.route('/check_freshness', methods=['GET'])
def check_freshness():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–≤–µ–∂–µ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö –∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç"""
    try:
        symbol = request.args.get('symbol', 'BTCUSDT')
        timeframe = request.args.get('timeframe', '1d')
        auto_update = request.args.get('auto_update', 'true').lower() == 'true'
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –∏–∑ main.py
        freshness_check = check_data_freshness(symbol, timeframe)
        
        # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ —É—Å—Ç–∞—Ä–µ–ª–∏ –∏ auto_update=true, –æ–±–Ω–æ–≤–ª—è–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
        if auto_update and freshness_check.get('needs_update'):
            print(f"üîÑ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol} {timeframe}")
            
            # –û—á–∏—â–∞–µ–º –∫—ç—à
            normalized_symbol = normalize_symbol(symbol)
            cache_patterns = [f"ohlcv_{normalized_symbol}", f"full_data_{normalized_symbol}"]
            cleared_count = 0
            
            for cache_file in CACHE_DIR.glob("*.pkl"):
                if any(pattern in cache_file.name for pattern in cache_patterns):
                    try:
                        cache_file.unlink()
                        cleared_count += 1
                        print(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω –∫—ç—à: {cache_file.name}")
                    except Exception as e:
                        print(f"‚ùå –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –∫—ç—à–∞ {cache_file.name}: {e}")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–≤–µ–∂–∏–µ –¥–∞–Ω–Ω—ã–µ
            from main import get_ohlcv_data
            fresh_data = get_ohlcv_data(timeframe, symbol)
            
            freshness_check['auto_updated'] = True
            freshness_check['cleared_cache_entries'] = cleared_count
            freshness_check['fresh_data_count'] = len(fresh_data) if not fresh_data.empty else 0
            
            if not fresh_data.empty:
                latest_date = fresh_data['date'].max()
                freshness_check['new_latest_date'] = latest_date.strftime('%Y-%m-%dT%H:%M:%SZ')
        
        return jsonify({
            'success': True,
            **freshness_check
        })
        
    except Exception as e:
        print(f"‚ùå Error in check_freshness: {str(e)}")
        return jsonify({
            'success': False, 
            'message': f'Error checking freshness: {str(e)}'
        }), 500
    
@pattern_bp.route('/refresh_data', methods=['POST'])
def refresh_data():
    """–ù–∞–¥–µ–∂–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö - –æ—Å–Ω–æ–≤–Ω–æ–π —ç–Ω–¥–ø–æ–∏–Ω—Ç"""
    try:
        data = request.get_json() or {}
        symbol = data.get('symbol', 'BTCUSDT')
        timeframe = data.get('timeframe', '1d')
        
        print(f"üîÑ –ó–ê–ü–£–°–ö –û–ë–ù–û–í–õ–ï–ù–ò–Ø –î–ê–ù–ù–´–•: {symbol} {timeframe}")
        
        normalized_symbol = normalize_symbol(symbol)
        
        # 1. –û–ß–ò–°–¢–ö–ê –ö–≠–®–ê
        cache_files = []
        patterns = [
            f"*ohlcv*{normalized_symbol}*",
            f"*full_data*{normalized_symbol}*", 
            f"*{normalized_symbol}*{timeframe}*"
        ]
        
        cleared_count = 0
        for pattern in patterns:
            for cache_file in CACHE_DIR.glob(pattern):
                if cache_file not in cache_files:
                    cache_files.append(cache_file)
        
        for cache_file in cache_files:
            try:
                if cache_file.exists():
                    cache_file.unlink()
                    cleared_count += 1
                    print(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω –∫—ç—à: {cache_file.name}")
            except Exception as e:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å {cache_file.name}: {e}")
        
        print(f"‚úÖ –û—á–∏—â–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –∫—ç—à–∞: {cleared_count}")
        
        # 2. –ü–ï–†–ï–ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• - –ó–ê–ì–†–£–ñ–ê–ï–ú –° 2017 –ì–û–î–ê

        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å 2017 –≥–æ–¥–∞
        start_date = "2017-01-01"
        end_date = (datetime.now() + timedelta(days=1)).strftime('%Y-%m-%d')
        
        print(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å {start_date} –ø–æ {end_date}")
        fresh_data = fetch_binance_ohlcv_fast(start_date, end_date, timeframe, normalized_symbol)
        
        if fresh_data.empty:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —Å 2017 –≥–æ–¥–∞, –ø—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥...")
            # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å 2020 –≥–æ–¥–∞ –∫–∞–∫ –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç
            start_date = "2020-01-01"
            fresh_data = fetch_binance_ohlcv_fast(start_date, end_date, timeframe, normalized_symbol)
        
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(fresh_data)}")
        
        if not fresh_data.empty:
            latest_date = fresh_data['date'].max()
            earliest_date = fresh_data['date'].min()
            print(f"üìÖ –î–∏–∞–ø–∞–∑–æ–Ω –¥–∞–Ω–Ω—ã—Ö: {earliest_date} - {latest_date}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
            cache_key = get_cache_key("full_data", normalized_symbol, timeframe)
            save_to_cache(cache_key, fresh_data)
            print("üíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –∫—ç—à")
        
        return jsonify({
            'success': True,
            'message': f'Data successfully refreshed for {normalized_symbol}',
            'cleared_cache_entries': cleared_count,
            'fresh_data_count': len(fresh_data),
            'earliest_date': fresh_data['date'].min().strftime('%Y-%m-%dT%H:%M:%SZ') if not fresh_data.empty else 'No data',
            'latest_date': fresh_data['date'].max().strftime('%Y-%m-%dT%H:%M:%SZ') if not fresh_data.empty else 'No data',
            'data_loaded': not fresh_data.empty
        })
        
    except Exception as e:
        print(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –í refresh_data: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False, 
            'message': f'Refresh failed: {str(e)}',
            'error_details': str(e)
        }), 500
    
@pattern_bp.route('/switch_data', methods=['POST'])
def switch_data():
    """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ —Å–º–µ–Ω–µ —Å–∏–º–≤–æ–ª–∞ –∏–ª–∏ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞"""
    try:
        data = request.get_json() or {}
        symbol = data.get('symbol', 'BTCUSDT')
        timeframe = data.get('timeframe', '1d')
        
        print(f"üîÑ –ü–ï–†–ï–ö–õ–Æ–ß–ï–ù–ò–ï –î–ê–ù–ù–´–•: {symbol}, –¢–§: {timeframe}")
        
        normalized_symbol = normalize_symbol(symbol)
        
        # –û–ß–ò–°–¢–ö–ê –ö–≠–®–ê –î–õ–Ø –ù–û–í–´–• –î–ê–ù–ù–´–•
        cache_patterns = [
            f"*ohlcv*{normalized_symbol}*",
            f"*full_data*{normalized_symbol}*", 
            f"*{normalized_symbol}*{timeframe}*"
        ]
        
        cleared_count = 0
        for pattern in cache_patterns:
            for cache_file in CACHE_DIR.glob(pattern):
                try:
                    if cache_file.exists():
                        cache_file.unlink()
                        cleared_count += 1
                        print(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω –∫—ç—à: {cache_file.name}")
                except Exception as e:
                    print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å {cache_file.name}: {e}")
        
        # –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• –° 2017 –ì–û–î–ê
        start_date = "2017-01-01"
        end_date = (datetime.now() + timedelta(days=1)).strftime('%Y-%m-%d')
        
        print(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {normalized_symbol} {timeframe} —Å {start_date} –ø–æ {end_date}")
        
        fresh_data = fetch_binance_ohlcv_fast(start_date, end_date, timeframe, normalized_symbol)
        
        if fresh_data.empty:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ, –ø—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥...")
            start_date = "2020-01-01"
            fresh_data = fetch_binance_ohlcv_fast(start_date, end_date, timeframe, normalized_symbol)
        
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(fresh_data)}")
        
        # –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• –î–õ–Ø –§–†–û–ù–¢–ï–ù–î–ê
        records = []
        if not fresh_data.empty:
            for _, row in fresh_data.iterrows():
                open_time = row['date']
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º close_time –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞
                if timeframe == '1h':
                    close_time = open_time + timedelta(hours=1)
                elif timeframe == '4h':
                    close_time = open_time + timedelta(hours=4)
                elif timeframe == '1d':
                    close_time = open_time + timedelta(days=1)
                elif timeframe == '1w':
                    close_time = open_time + timedelta(weeks=1)
                else:
                    close_time = open_time + timedelta(days=1)
                
                records.append({
                    'open_time': open_time.strftime('%Y-%m-%dT%H:%M:%SZ'),
                    'close_time': close_time.strftime('%Y-%m-%dT%H:%M:%SZ'),
                    'open_price': float(row['open']),
                    'close_price': float(row['close']),
                    'high': float(row['high']),
                    'low': float(row['low']),
                    'volume': float(row['volume']),
                    'timeframe': timeframe,
                    'symbol': symbol
                })
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
            cache_key = get_cache_key("full_data", normalized_symbol, timeframe)
            save_to_cache(cache_key, fresh_data)
            print("üíæ –ù–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –∫—ç—à")
        
        return jsonify({
            'success': True,
            'message': f'Data switched to {normalized_symbol} {timeframe}',
            'candles': records,
            'candles_count': len(records),
            'earliest_date': fresh_data['date'].min().strftime('%Y-%m-%dT%H:%M:%SZ') if not fresh_data.empty else None,
            'latest_date': fresh_data['date'].max().strftime('%Y-%m-%dT%H:%M:%SZ') if not fresh_data.empty else None,
            'cleared_cache_entries': cleared_count
        })
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False, 
            'message': f'Switch data failed: {str(e)}'
        }), 500
    
@pattern_bp.route('/ohlcv_fast', methods=['GET'])
def api_ohlcv_fast():
    """–ë—ã—Å—Ç—Ä–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ OHLCV –¥–∞–Ω–Ω—ã—Ö (—Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–∞–Ω–Ω—ã–µ)"""
    try:
        timeframe = request.args.get('timeframe', '1d')
        symbol = request.args.get('symbol', 'BTCUSDT')
        
        print(f"‚ö° –ë–´–°–¢–†–ê–Ø –∑–∞–≥—Ä—É–∑–∫–∞: {symbol} {timeframe}")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–µ—Ä–∏–æ–¥ –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
        end_date = datetime.now()
        
        if timeframe == '1h':
            start_date = end_date - timedelta(days=180)  # 6 –º–µ—Å—è—Ü–µ–≤
        elif timeframe == '4h':
            start_date = end_date - timedelta(days=360)  # 1 –≥–æ–¥
        else:
            start_date = end_date - timedelta(days=720)  # 2 –≥–æ–¥–∞
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é —Ñ—É–Ω–∫—Ü–∏—é, –Ω–æ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–º –¥–∏–∞–ø–∞–∑–æ–Ω–æ–º
        result = api_get_ohlcv_data(
            start_date=start_date.strftime('%Y-%m-%d'),
            end_date=end_date.strftime('%Y-%m-%d'),
            timeframe=timeframe,
            symbol=symbol
        )
        
        if result['success']:
            print(f"‚úÖ –ë—ã—Å—Ç—Ä–∞—è –∑–∞–≥—Ä—É–∑–∫–∞: {symbol} {timeframe} - {len(result.get('candles', []))} —Å–≤–µ—á–µ–π")
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ –±—ã—Å—Ç—Ä–æ–π –∑–∞–≥—Ä—É–∑–∫–∏: {symbol} {timeframe}")
            
        return jsonify(result)
            
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ api_ohlcv_fast: {str(e)}")
        return jsonify({'success': False, 'message': str(e)}), 500